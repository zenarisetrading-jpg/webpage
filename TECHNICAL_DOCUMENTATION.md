# PPC Suite V4 - Technical Documentation

## Table of Contents
1. [Architecture Overview](#architecture-overview)
2. [Core Modules](#core-modules)
3. [Optimizer Module](#optimizer-module)
4. [ASIN Mapper Module](#asin-mapper-module)
5. [Creator Module](#creator-module)
6. [Data Flow & Integration](#data-flow--integration)
7. [Assistant Module (AI)](#assistant-module-ai)
8. [Configuration & Constants](#configuration--constants)
9. [Account Security & Management](#account-security--management)
10. [v4.3 Release Notes](#v43-release-notes)

---

## Architecture Overview

### System Design

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ppcsuite_v4.py                      â”‚
â”‚                  (Main Orchestrator)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚               â”‚               â”‚
        â–¼               â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Data Hub   â”‚  â”‚ Features â”‚  â”‚ UI Componentsâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚               â”‚               â”‚
        â”‚         â”Œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”         â”‚
        â”‚         â”‚     â”‚     â”‚         â”‚
        â–¼         â–¼     â–¼     â–¼         â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”
   â”‚ Loader â”‚  â”‚Opt.â”‚â”‚ASINâ”‚â”‚Creaâ”‚â”‚   â”‚Layoutâ”‚
   â”‚ Mapper â”‚  â”‚    â”‚â”‚Map.â”‚â”‚tor â”‚   â”‚Cards â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”˜
        â”‚         â”‚     â”‚     â”‚
        â”‚         â–¼     â–¼     â–¼
        â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â””â”€â”€â”€â”€â”€â–¶â”‚  Shared Utils  â”‚
               â”‚ (Matchers, etc)â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚   Assistant    â”‚
               â”‚   (AI Brain)   â”‚â—€â”
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                        â–²         â”‚
                        â”‚         â”‚
                   Read Context   â”‚
                        â”‚         â”‚
                 â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”
                 â”‚ Knowledge Graph â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Module Responsibilities

| Module | Purpose | Input | Output |
|--------|---------|-------|--------|
| **Optimizer** | Bid optimization, harvest detection, negative detection | Search Term Report | Bid changes, harvest list, negatives |
| **ASIN Mapper** | ASIN intelligence, competitor detection | Search Term Report | Flagged ASINs, categories |
| **Creator** | Campaign creation (Launch & Harvest) | Harvest list / User Inputs | Amazon bulk upload file |
| **Assistant** | AI Strategic Analysis | Full Context | Chat responses, strategic insights |
| **Data Hub** | Centralized data loading & enrichment | CSV/Excel files | Standardized DataFrames |
| **Impact Dashboard** | Historical performance tracking | Action Logs | Sales/Spend Impact Charts |

---

## Core Modules

### Data Hub (`core/data_hub.py`)

**Purpose**: Centralized file upload and data enrichment across all modules.

**Key Functions**:
- `load_data(file_key, uploaded_file)` - Load and standardize report data
- `get_enriched_data()` - Merge search term + purchased product reports + Smart Category Fallback
- `is_loaded(key)` - Check if specific report exists

**Data Keys**:
- `search_term_report` - Main PPC metrics source
- `purchased_product_report` - SKU mapping for enrichment
- `advertised_product_report` - Brand/ASIN ownership

---

## Optimizer Module

### Overview

**File**: `features/optimizer.py` (1989 lines)

**Purpose**: Complete PPC optimization engine with:
1. Harvest detection (high-performing search terms)
2. Negative detection (isolation + performance bleeders)
3. Bid optimization (ROAS-based)
4. Performance simulation

### Configuration

```python
DEFAULT_CONFIG = {
    # Harvest Thresholds
    'HARVEST_ROAS_THRESHOLD': 3.5,
    'HARVEST_MIN_CLICKS': 10,
    'HARVEST_MIN_SPEND': 20,
    
    # Negative Thresholds
    'NEGATIVE_CLICKS_THRESHOLD': 10,
    'NEGATIVE_SPEND_THRESHOLD': 15,
    
    # Bid Optimization
    'ROAS_TARGET': 2.5,
    'BID_MIN': 0.15,
    'BID_MAX': 5.00,
    'ALPHA': 0.15  # Learning rate
}
```

### Workflow

#### Stage 1: Data Preparation

```
prepare_data(df, config)
  â”œâ”€ Validate required columns
  â”œâ”€ Normalize column names
  â”œâ”€ Calculate derived metrics (ROAS, CPC)
  â”œâ”€ Detect date range for weekly normalization
  â””â”€ Return (prepared_df, date_info)
```

**Key Logic**:
```python
# ROAS calculation
df['ROAS'] = df['Sales'] / df['Spend']  # Where Spend > 0

# Date detection for weekly normalization
num_weeks = (max_date - min_date).days / 7
```

---

#### Stage 2: Harvest Detection

```
identify_harvest_candidates(df, config, matcher)
  â”œâ”€ Filter by performance thresholds
  â”‚   â””â”€ ROAS >= 3.5 AND Clicks >= 10 AND Spend >= 20
  â”œâ”€ Check if already running exact match
  â”‚   â””â”€ ExactMatcher.is_exact_running(term)
  â”œâ”€ Select winner campaign for each term
  â”‚   â””â”€ Highest ROAS, break ties by Sales, then Clicks
  â””â”€ Return harvest_df with winner campaigns
```

**Winner Selection Logic**:
```python
if term appears in multiple campaigns:
    winner = campaign with:
        1. Highest ROAS
        2. If ROAS tied â†’ Highest Sales
        3. If Sales tied â†’ Highest Clicks
```

**Output Columns**:
- `Customer Search Term`, `ROAS`, `Clicks`, `Sales`, `Spend`
- `Campaign Name` (winner), `SKU` (if enriched)
- `Is_ASIN` flag

---

#### Stage 3: Negative Detection

```
identify_negative_candidates(df, config, harvest_df)
  â”œâ”€ Stage 3.1: Isolation Negatives
  â”‚   â”œâ”€ Find harvested terms in NON-exact campaigns
  â”‚   â”œâ”€ Aggregate by (Campaign, Ad Group, Term)
  â”‚   â”œâ”€ Exclude winner campaigns
  â”‚   â””â”€ Flag for negation in source campaigns
  â”‚
  â”œâ”€ Stage 3.2: Performance Negatives (Bleeders)
  â”‚   â”œâ”€ Filter: Sales == 0 AND non-exact match
  â”‚   â”œâ”€ Aggregate by (Campaign, Ad Group, Term)
  â”‚   â”œâ”€ Apply thresholds (Default):
  â”‚   â”‚   â””â”€ Clicks >= 10 OR Spend >= 10
  â”‚   â”œâ”€ Classify Severity:
  â”‚   â”‚   â”œâ”€ ðŸ”´ Hard Stop: Clicks >= 15 (Statistically confirmed failure)
  â”‚   â”‚   â””â”€ ðŸŸ¡ Performance: Meets min threshold (Wasting money)
  â”‚   â””â”€ Add to negatives list (Action: Negative Exact)
  â”‚
  â””â”€ Stage 3.3: ASIN Mapper Integration
      â”œâ”€ Read session_state['latest_asin_analysis']
      â”œâ”€ Extract competitor ASINs
      â”œâ”€ Deduplicate against existing negatives
      â”‚   â””â”€ Check (Campaign, AdGroup, Term) uniqueness
      â”œâ”€ Track stats: total, added, duplicates
      â””â”€ Return (neg_kw_df, neg_pt_df, your_products_df)
```

**Critical De-duplication**:
```python
seen_keys = set()
for negative in [isolation, bleeders, asin_mapper]:
    key = (campaign, ad_group, term.lower())
    if key in seen_keys:
        skip  # Prevent duplicates
    seen_keys.add(key)
```

**Isolation Example**:
```
Term "phone case" harvested to Campaign_Exact
â”œâ”€ Found in Campaign_Broad â†’ NEGATE
â”œâ”€ Found in Campaign_Auto â†’ NEGATE
â””â”€ Found in Campaign_Exact â†’ SKIP (winner)
```

**Output**:
- `neg_kw` - Negative keywords (negativeExact match type)
- `neg_pt` - Negative ASIN product targets
- `your_products` - User's ASINs needing manual review

---

#### Stage 4: Bid Optimization

```
calculate_bid_optimizations(df, config, harvested_terms)
  â”œâ”€ Segment data:
  â”‚   â”œâ”€ Direct (High Granularity): Exact, Broad, Phrase, Auto (with targets)
  â”‚   â”‚   â””â”€ Process every keyword/target individually to preserve specific text
  â”‚   â””â”€ Aggregated (Fallback): Only undefined generic targets (rare)
  â”‚
  â”œâ”€ Process Direct Segment
  â”‚   â”œâ”€ Group by (Campaign, AdGroup, Keyword/PT)
  â”‚   â”œâ”€ Calculate optimal bid using ROAS formula
  â”‚   â””â”€ Return direct_bids_df
  â”‚
  â””â”€ Process Aggregated Segment
      â”œâ”€ Aggregate to match type level
      â”‚   â””â”€ Group by (Campaign, AdGroup, Targeting, MatchType)
      â”œâ”€ Calculate optimal bid for aggregate
      â””â”€ Return agg_bids_df
```

**Bid Calculation Formula**:
```python
def _optimize_bid(row, config, alpha=0.15):
    current_bid = row['Cost Per Click (CPC)']
    roas = row['ROAS']
    target_roas = config['ROAS_TARGET']
    
    if roas < target_roas:
        # Underperforming â†’ Decrease bid
        adjustment = -(1 - roas / target_roas)
    else:
        # Overperforming â†’ Increase bid
        adjustment = (roas / target_roas - 1)
    
    new_bid = current_bid * (1 + alpha * adjustment)
    new_bid = max(config['BID_MIN'], min(new_bid, config['BID_MAX']))
    
    return new_bid
```

**Aggregation Logic**:
```python
# Don't optimize at search term level for non-exact!
# Aggregate back to targeting level

Group: (Campaign, AdGroup, "keyword:shoe", "broad")
  â”œâ”€ Search term: "red shoes" â†’ 100 clicks, AED 50
  â”œâ”€ Search term: "blue shoes" â†’ 50 clicks, AED 30
  â””â”€ Aggregate: 150 clicks, AED 80 â†’ Calculate ONE bid
```

---

#### Stage 5: Heatmap Generation

```
create_heatmap(df, config, harvest_df, neg_kw, neg_pt, direct_bids, agg_bids)
  â”œâ”€ Group by (Campaign, Ad Group)
  â”œâ”€ Calculate aggregate metrics
  â”œâ”€ Assign priority colors:
  â”‚   â”œâ”€ ðŸ”´ High: ROAS < 1.5 AND Spend > 100
  â”‚   â”œâ”€ ðŸŸ¡ Medium: ROAS < 2.5 OR Spend > 50
  â”‚   â””â”€ ðŸŸ¢ Good: ROAS >= 2.5
  â”œâ”€ Track optimizer actions:
  â”‚   â”œâ”€ Count harvests from this group
  â”‚   â”œâ”€ Count negatives from this group
  â”‚   â””â”€ Count bid changes from this group
  â””â”€ Return heatmap_df with action tracking
```

**Output Columns**:
- Metrics: `Clicks`, `Spend`, `Sales`, `ROAS`, `ACoS`
- Priority: `ðŸ”´ High | ðŸŸ¡ Medium | ðŸŸ¢ Good`
- Actions: `Harvests`, `Negatives`, `Bid Changes`

---

#### Stage 6: Simulation

```
run_simulation(df, direct_bids, agg_bids, harvest_df, config, date_info)
  â”œâ”€ Calculate baseline (current performance)
  â”œâ”€ Normalize to monthly projections (x4.33 weeks)
  â”œâ”€ Forecast 3 scenarios:
  â”‚   â”œâ”€ Conservative (70% probability)
  â”‚   â”‚   â””â”€ Elasticity: CPCâ†‘ â†’ Clicksâ†“ (0.4x), CVRâ†‘ (0.05x)
  â”‚   â”œâ”€ Expected (25% probability)
  â”‚   â”‚   â””â”€ Elasticity: CPCâ†‘ â†’ Clicksâ†“ (0.7x), CVRâ†‘ (0.1x)
  â”‚   â””â”€ Aggressive (5% probability)
  â”‚       â””â”€ Elasticity: CPCâ†‘ â†’ Clicksâ†‘ (0.95x), CVRâ†‘ (0.15x)
  â”œâ”€ Calculate impact for each scenario
  â””â”€ Return weighted average forecast
```

**Elasticity Model**:
```python
# Conservative scenario
if bid increases by 10%:
    clicks decrease by 4% (0.4 elasticity)
    CVR increases by 0.5% (absolute)
    
# Harvest efficiency multiplier
harvest_sales = harvest_clicks * baseline_cvr * 1.30  # +30% efficiency
```

---

## ASIN Mapper Module

### Overview

**File**: `features/asin_mapper.py` (725 lines)

**Purpose**: Automatic ASIN detection, API lookup, categorization, and negative suggestion

### Workflow

```
analyze(data)
  â”œâ”€ Step 1: Detect ASIN Searches
  â”‚   â””â”€ Regex: \b[bB]0[a-zA-Z0-9]{8}\b
  â”‚
  â”œâ”€ Step 2: Aggregate by ASIN + Campaign + Ad Group
  â”‚   â”œâ”€ Group by (ASIN, Campaign Name, Ad Group Name)
  â”‚   â”œâ”€ Sum: Impressions, Clicks, Spend, Orders
  â”‚   â””â”€ Flag: Converting (Orders > 0)
  â”‚
  â””â”€ Step 3: Prioritize for API Lookup
      â”œâ”€ Filter non-converting ASINs
      â”œâ”€ Apply thresholds:
      â”‚   â””â”€ Clicks >= 10 AND Spend >= 15
      â””â”€ Return top 30 by spend
```

**Key Change (Per-Campaign Tracking)**:
```python
# OLD (Wrong): Aggregated globally
agg = data.groupby('ASIN').sum()
# If ASIN works in Campaign A but bleeds in Campaign B
# â†’ Would flag for ALL campaigns (WRONG!)

# NEW (Correct): Per campaign/ad-group
agg = data.groupby(['ASIN', 'Campaign Name', 'Ad Group Name']).sum()
# â†’ Only flags campaigns where it bleeds (CORRECT!)
```

---

### API Lookup & Enrichment

```
display_results(results)
  â”œâ”€ Show initial summary (ASINs found, priority count)
  â”œâ”€ User clicks "Lookup ASINs"
  â”‚   â”‚
  â”‚   â”œâ”€ Initialize Rainforest API client
  â”‚   â”œâ”€ For each high-priority ASIN:
  â”‚   â”‚   â”œâ”€ Call API: client.lookup_asin(asin)
  â”‚   â”‚   â”œâ”€ Merge stats from aggregation:
  â”‚   â”‚   â”‚   â”œâ”€ original_clicks, original_spend
  â”‚   â”‚   â”‚   â”œâ”€ Campaign Name, Ad Group Name  â† PRESERVED
  â”‚   â”‚   â”‚   â””â”€ CampaignId, AdGroupId (if available)
  â”‚   â”‚   â””â”€ Add to details_df
  â”‚   â”‚
  â”‚   â”œâ”€ Categorize each ASIN:
  â”‚   â”‚   â””â”€ _categorize_asin(row)
  â”‚   â”‚       â”œâ”€ Check if in uploaded ASIN list â†’ YOUR_PRODUCT
  â”‚   â”‚       â”œâ”€ Check brand match â†’ YOUR_PRODUCT
  â”‚   â”‚       â””â”€ Otherwise â†’ COMPETITOR
  â”‚   â”‚
  â”‚   â”œâ”€ Flag for negation:
  â”‚   â”‚   â””â”€ Competitors with Clicks >= 10 AND Spend >= 15
  â”‚   â”‚
  â”‚   â””â”€ Format for Optimizer:
  â”‚       â””â”€ _format_for_optimizer(flagged, competitors, your_products)
  â”‚
  â””â”€ Display enriched results
      â”œâ”€ Flagged ASINs (auto-negate competitors)
      â”œâ”€ Your products (manual review)
      â””â”€ Diagnostic cards (detailed product info)
```

---

### Optimizer Integration

```
_format_for_optimizer(flagged_competitors, all_competitors, your_products)
  â”œâ”€ Competitor ASINs (auto-negate):
  â”‚   â””â”€ Format: {
  â”‚         "Type": "ASIN Mapper - Competitor",
  â”‚         "Campaign Name": row['Campaign Name'],  â† Preserved!
  â”‚         "Ad Group Name": row['Ad Group Name'],    â† Preserved!
  â”‚         "Term": asin,
  â”‚         "Is_ASIN": True,
  â”‚         "Clicks": clicks,
  â”‚         "Spend": spend
  â”‚       }
  â”‚
  â””â”€ Your Products (manual review):
      â””â”€ Format: {
            "Term": asin,
            "Brand": brand,
            "Product": title,
            "Clicks": clicks,
            "Spend": spend,
            "Recommendation": generate_recommendation(row)
          }
          
generate_recommendation(row):
    if spend > 50:
        return "âš ï¸ High waste - review urgently"
    elif clicks > 30:
        return "âš ï¸ Many clicks, 0 orders - likely wrong"
    else:
        return "â„¹ï¸ Low volume - monitor"
```

**Session State Storage**:
```python
st.session_state['latest_asin_analysis'] = {
    'asin_details': details_df,
    'competitors': competitors_df,
    'your_products': your_products_df,
    'flagged_for_negation': flagged_df,
    'optimizer_negatives': {  â† For Optimizer integration
        'competitor_asins': [...],
        'your_products_review': [...]
    }
}
```

---

## Creator Module

### Overview

**File**: `features/creator.py` (Unified Launch & Harvest)

**Purpose**: A unified tool for both cold-starting new products and harvesting proven winners.

### Dual Modes

#### Tab 1: ðŸš€ Launch New Product
**Goal:** Create full-funnel structure for cold starts.
*   **Inputs:** SKU, Price, Target ACOS, Budget.
*   **Smart Logic:**
    *   **Base Bid:** `Price * CVR * Target ACOS`.
    *   **Budget Split:** Weighted allocation (Auto > Manual Keywords > PT).
    *   **Structure:**
        *   **Auto:** Close-match (1.5x bid), Loose-match (1.2x), Substitutes (0.8x), Complements (1.0x).
        *   **Manual:** Waterfall structure (Exact [Top 5] > Phrase [Next 7] > Broad [Rest]).
        *   **Product Targeting:** Competitor ASINs (Bid * 1.1).

#### Tab 2: ðŸŒ¾ Harvest Winners
**Goal:** Scale high-performing search terms from Optimizer.
*   **Momentum Bidding:** `Bid = Actual CPC * 1.1` (Safe scaling).
*   **Structure:**
    *   **Weekly Consolidation:** All harvests for the week go into `HarvestExact_WK{Week}_{Year}`.
    *   **SKU Grouping:** One Ad Group per SKU (`AG_KW_Exact_{SKU}...`).
    *   **Smart Mapping:** Auto-maps SKUs using the "Purchased Product Report" from Data Hub.

### Workflow

```
render_ui()
  â”œâ”€ Tab 1: _render_launch_tab()
  â”‚   â””â”€ User Input -> _generate_launch_bulk_rows()
  â”‚
  â””â”€ Tab 2: _render_harvest_tab()
      â”œâ”€ Load candidates from Session State
      â”œâ”€ Auto-map SKUs (Data Hub lookup)
      â””â”€ Button -> generate_harvest_bulk_file()
```

---

### Account Health Diagnostics
**(New in v4.1)** - Replaced "Projected Impact" tiles with factual diagnostics to avoid Simulation conflict.

**Method**: `_calculate_account_health(df, r)`

**Metrics**:
1.  **Health Score (0-100)**: Composite of ROAS (40%), Waste Ratio (40%), CVR (20%).
2.  **Waste Ratio**: % of spend on terms with 0 orders.
3.  **Optimization Coverage**: % of search terms covered by Negatives/Harvests.
4.  **Current ROAS**: Actual realized ROAS (vs projected).

**Logic**:
```python
health_score = (roas_score * 0.4 + waste_score * 0.4 + cvr_score * 0.2)
# where roas_score = min(100, current_roas / 4.0 * 100)
```

---

## Assistant Module (AI)

### Overview

**File**: `features/assistant.py` (rewritten v4.2)

**Purpose**: "Deep Strategist" AI that uses a **Knowledge Graph** to provide context-aware insights rather than simple data summaries.

### Architecture: The Knowledge Graph

Instead of feeding raw rows to the LLM, we construct a structured JSON context:

```python
knowledge_graph = {
    "strategic_insights": {
        "market_position": "Aggressive scaling (ROAS > 4.0)",
        "inefficiency_detection": "High waste in 'Generic' portfolio"
    },
    "cross_references": {
        "harvest_negative_paradox": ["term 'x' bleeds in Campaign A but converts in Campaign B"]
    },
    "patterns_detected": {
        "semantic_themes": ["'stainless steel' terms have 30% higher CVR"]
    },
    "impact_forecast": {
        "savings": "AED 1,200/mo",
        "upside": "AED 4,500/mo"
    }
}
```

### Prompt Engineering

**System Prompt**: Enforces a "Senior Strategist" persona.
1.  **Scan Knowledge Graph**: Look for pre-computed anomalies.
2.  **Cross-Reference**: Check conflicting signals (e.g. Harvest + Negative).
3.  **Root Cause Analysis**: Why is it bleeding? (Competitor? Intent mismatch?).
4.  **Quantify Impact**: Use the dollar values from the forecast.
5.  **Actionable Advice**: specific campaign/bid changes.

---

## Data Flow & Integration

### Module Integration Flow

```
1. User Workflow
   â””â”€ Upload Search Term Report â†’ Data Hub
      â”‚
      â”œâ”€ Navigate to Optimizer
      â”‚   â”œâ”€ Analyze & Optimize
      â”‚   â”œâ”€ Get: Harvest list, Negatives, Bid changes
      â”‚   â””â”€ Download bulk files
      â”‚
      â”œâ”€ Navigate to ASIN Mapper
      â”‚   â”œâ”€ Auto-detect ASINs from same report
      â”‚   â”œâ”€ Lookup via API
      â”‚   â”œâ”€ Categorize & flag competitors
      â”‚   â””â”€ Integration â†’ Flows to Optimizer Negatives
      â”‚
      â””â”€ Navigate to Creator
          â”œâ”€ Upload harvest list (from Optimizer)
          â”œâ”€ Upload SKU mapping report
          â””â”€ Generate campaign bulk file

2. Cross-Module Integration
   
   ASIN Mapper â†’ Optimizer:
      st.session_state['latest_asin_analysis']['optimizer_negatives']
      â””â”€ Read in identify_negative_candidates() Stage 3
      
   Optimizer â†’ Creator:
      Download harvest.xlsx
      â””â”€ Upload in Creator UI
      
   Data Hub â†’ All Modules:
      DataHub.get_data('search_term_report')
      â””â”€ Standard DataFrame with mapped columns
```

---

### Session State Architecture

```python
st.session_state = {
    # Data Hub
    'data': {
        'search_term_report': DataFrame,
        'purchased_product_report': DataFrame,
        'advertised_product_report': DataFrame
    },
    
    # Optimizer
    'latest_optimizer_run': {
        'df': prepared_df,
        'date_info': {...},
        'harvest': harvest_df,
        'neg_kw': neg_kw_df,
        'neg_pt': neg_pt_df,
        'your_products_review': your_products_df,  â† NEW
        'direct_bids': direct_bids_df,
        'agg_bids': agg_bids_df,
        'heatmap': heatmap_df,
        'simulation': simulation_dict
    },
    
    # ASIN Mapper
    'latest_asin_analysis': {
        'asin_details': details_df,
        'competitors': competitors_df,
        'your_products': your_products_df,
        'flagged_for_negation': flagged_df,
        'optimizer_negatives': {  â† Integration point
            'competitor_asins': [...],
            'your_products_review': [...]
        }
    },
    
    # Integration Stats
    'asin_mapper_integration_stats': {
        'total': 27,
        'added': 0,
        'duplicates': 27
    }
}
```

---

## Configuration & Constants

### Required Environment Variables

**File**: `.streamlit/secrets.toml`

```toml
RAINFOREST_API_KEY = "your_rainforest_api_key"
ANTHROPIC_API_KEY = "your_anthropic_api_key"
USER_BRANDS = ["s2c", "yourbrand", "zenarisetrading"]
USER_ASINS = ["B09...", "B08..."]
```

---

### Optimizer Thresholds

| Parameter | Default | Purpose |
|-----------|---------|---------|
| `HARVEST_ROAS_THRESHOLD` | 3.5 | Min ROAS to harvest |
| `HARVEST_MIN_CLICKS` | 10 | Min clicks to harvest |
| `HARVEST_MIN_SPEND` | 20 AED | Min spend to harvest |
| `NEGATIVE_CLICKS_THRESHOLD` | 10 | Min clicks to negate |
| `NEGATIVE_SPEND_THRESHOLD` | 10 AED | Min spend to negate |
| `ROAS_TARGET` | 2.5 | Target ROAS for bids |
| `BID_MIN` | 0.15 AED | Min bid allowed |
| `BID_MAX` | 5.00 AED | Max bid allowed |
| `ALPHA` | 0.15 | Bid adjustment learning rate |

---

### ASIN Mapper Thresholds

| Parameter | Default | Purpose |
|-----------|---------|---------|
| `min_clicks` | 10 | Min clicks for high priority |
| `min_wasted_spend` | 15 AED | Min spend for high priority |
| `bleeder_clicks` | 10 | Flagging threshold (competitors) |
| `bleeder_spend` | 15 AED | Flagging threshold (competitors) |

---

## API Integrations

### Rainforest API (ASIN Lookups)

**File**: `api/rainforest_client.py`

**Endpoint**: `https://api.rainforestapi.com/request`

**Request**:
```python
params = {
    'api_key': api_key,
    'type': 'product',
    'asin': asin,
    'amazon_domain': 'amazon.ae'  # or .com, .uk, etc
}
response = requests.get(url, params=params)
```

**Response Parsing**:
```python
product = response.json()['product']

title = product.get('title', '')
brand = product.get('brand', '')
          OR product['buybox_winner'].get('brand', '')
          OR product['specifications'][...]['value']  # Fallback in specs
          
seller = product['buybox_winner'].get('name', '')
price = product['buybox_winner']['price'].get('value')
category = ' > '.join([c['name'] for c in product['categories']])
```

**Caching**: 
- In-memory cache by ASIN + marketplace
- Prevents redundant API calls

---

## Error Handling & Edge Cases

### Optimizer

**Edge Case**: Term appears in multiple campaigns
- **Solution**: Winner selection by ROAS â†’ Sales â†’ Clicks

**Edge Case**: ASIN suggested for negation already in bleeder list
- **Solution**: Deduplication by (Campaign, AdGroup, Term) key

**Edge Case**: Insufficient data for bid optimization
- **Solution**: Skip bid if Clicks < 5

### ASIN Mapper

**Edge Case**: API credits exhausted
- **Solution**: Display clear error message, suggest paid plan

**Edge Case**: ASIN works in Campaign A, bleeds in Campaign B
- **Solution**: Per-campaign aggregation ensures Campaign B gets flagged, not A

**Edge Case**: Brand name variations ("S2C" vs "s2c trading")
- **Solution**: Case-insensitive substring matching

---

## Testing & Validation

### Optimizer Validation Checks

1. **No term harvested AND negated in same campaign** âœ“
2. **Negatives unique per (Campaign, AdGroup, Term)** âœ“
3. **Bid changes within [BID_MIN, BID_MAX] range** âœ“
4. **Simulation totals match baseline + changes** âœ“

### ASIN Mapper Validation Checks

1. **Campaign/AdGroup preserved through API lookup** âœ“
2. **Deduplication against bleeder list** âœ“
3. **User feedback when all ASINs are duplicates** âœ“
4. **ASIN regex matches valid Amazon format** âœ“

---

## Future Enhancements

### Planned Features

1. **Category Matching**
   - Compare ASIN category vs campaign category
   - Auto-recommend Keep/Negate based on category match

2. **Historical Trend Analysis**
   - Track ASIN performance over time
   - Alert when performance degrades

3. **Budget Pacing**
   - Monitor daily spend vs budget
   - Auto-adjust bids if overspending

4. **Multi-Marketplace Support**
   - Unified dashboard for .ae, .sa, .eg
   - Cross-marketplace ASIN analysis

---

## Account Security & Management

### Strict Account Validation (v4.3)
**Objective:** Prevent data leakage between accounts ("Ghost Account" issue).

**Mechanism:**
1. **DB Validation:** Every page load validates `active_account_id` against the SQLite `accounts` table.
2. **Session Clearing:** Switching accounts triggers an immediate wipe of:
   - `unified_data` (Data Hub cache)
   - `optimizer_results` (Analysis cache)
   - `impact_analysis_cache`
3. **No Implicit Parsing:** Removed logic that inferred `client_id` from campaign names, ensuring data is ONLY attributed to the explicitly active account.

---

## v4.3 Release Notes (Dec 2025)

### Core Hardening
- **Ghost Account Fix:** Validated single source of truth for Account ID.
- **Smart Category Fallback:** Data Hub now auto-links Categories to Ad Groups if `Ad Group Name == SKU`, removing the strict dependency on the Advertised Product Report.
- **Indentation Fix:** Resolved syntax error in Data Hub fallback logic.

### UX Polish
- **Waterfall Chart:** "Total" bar is now grounded (Total) instead of floating (Relative).
- **Metric Clarity:** Replaced ambiguous "ROI" (which causes confusion on negative values) with "Profit Impact ($)".
- **Tooltips:** Added explanatory tooltips to all Impact Dashboard tiles and Optimizer Context widgets.

---

## Deployment & Production

### Requirements

- Python 3.8+
- Streamlit 1.28+
- Dependencies: `pandas`, `requests`, `openpyxl`, `anthropic`

### Launch Commands

```bash
# Local development
streamlit run ppcsuite_v4.py

# Production (with SSL)
streamlit run ppcsuite_v4.py --server.port 8501 --server.address 0.0.0.0
```

### File Structure Checklist

```
ppcsuite_refactored/
â”œâ”€â”€ ppcsuite_v4.py          âœ“ Main entry point
â”œâ”€â”€ .streamlit/
â”‚   â””â”€â”€ secrets.toml        âœ“ API keys, config
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ data_hub.py         âœ“ Centralized data loading
â”‚   â””â”€â”€ data_loader.py      âœ“ CSV/Excel processing
â”œâ”€â”€ features/
â”‚   â”œâ”€â”€ optimizer.py        âœ“ Bid optimization engine
â”‚   â”œâ”€â”€ asin_mapper.py      âœ“ ASIN intelligence
â”‚   â”œâ”€â”€ assistant.py        âœ“ AI Strategist (New)
â”‚   â”œâ”€â”€ ai_insights.py      âœ“ Semantic Clustering (New)
â”‚   â”œâ”€â”€ impact_dashboard.py âœ“ Active/Dormant Analysis
â”‚   â””â”€â”€ creator.py          âœ“ Unified Launch & Harvest
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ rainforest_client.py âœ“ ASIN API client
â”‚   â””â”€â”€ anthropic_client.py  âœ“ AI Client
â””â”€â”€ utils/
    â”œâ”€â”€ matchers.py         âœ“ Exact match detection
    â””â”€â”€ formatters.py       âœ“ Output formatting
```

---

## Appendix: Key Algorithms

### Winner Selection (Harvest)

```python
def select_winner(term_group):
    """Select winning campaign for a harvested term."""
    return term_group.sort_values(
        by=['ROAS', 'Sales', 'Clicks'],
        ascending=[False, False, False]
    ).iloc[0]
```

### ROAS-Based Bid Adjustment

```python
def calculate_new_bid(current_cpc, roas, target_roas=2.5, alpha=0.15):
    """Calculate optimal bid using ROAS elasticity."""
    if roas < target_roas:
        adjustment = -(1 - roas / target_roas)  # Decrease
    else:
        adjustment = (roas / target_roas - 1)   # Increase
    
    return current_cpc * (1 + alpha * adjustment)
```

### Campaign-Level Deduplication

```python
def deduplicate_negatives(negatives_list):
    """Ensure unique negatives per campaign/ad-group."""
    seen = set()
    unique = []
    
    for neg in negatives_list:
        key = (
            neg['Campaign Name'],
            neg['Ad Group Name'],
            neg['Term'].lower()
        )
        if key not in seen:
            seen.add(key)
            unique.append(neg)
    
    return unique
```

---

**Document Version**: 1.0  
**Last Updated**: 2025-12-10  
**Maintained By**: Development Team
